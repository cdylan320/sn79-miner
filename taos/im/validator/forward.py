# SPDX-FileCopyrightText: 2025 Rayleigh Research <to@rayleigh.re>
# SPDX-License-Identifier: MIT
# The MIT License (MIT)
# Copyright © 2023 Yuma Rao
# Copyright © 2025 Rayleigh Research

# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the “Software”), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
# and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all copies or substantial portions of
# the Software.

# THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
# THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

import time
import bittensor as bt
import uvloop
import asyncio
import aiohttp
import posix_ipc
import struct
import traceback
import pickle
from typing import List

from taos.im.neurons.validator import Validator
from taos.im.protocol import FinanceAgentResponse, FinanceEventNotification, MarketSimulationStateUpdate
from taos.im.protocol.instructions import *
from taos.im.validator.reward import set_delays
from taos.im.utils import duration_from_timestamp

asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

class DendriteManager:
    @staticmethod
    def configure_session(validator):
        """
        Ensures the validator's dendrite client session is properly configured.

        Creates a new aiohttp session if none exists or the previous one is closed.
        Reuses an existing session if available.

        Args:
            validator (Validator): The validator whose dendrite session should be configured.
        Returns:
            None
        """
        if not validator.dendrite._session or validator.dendrite._session.closed:
            connector = aiohttp.TCPConnector(
                ssl=False,
                limit=0,
                limit_per_host=0,
                ttl_dns_cache=300,
                enable_cleanup_closed=True,
            )

            timeout = aiohttp.ClientTimeout(
                total=validator.config.neuron.timeout,
                connect=1.0,
                sock_read=None,
                sock_connect=1.0,
            )

            validator.dendrite._session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                skip_auto_headers={'User-Agent'},
            )
            bt.logging.debug("Created new aiohttp session")
        else:
            bt.logging.debug("Reusing existing aiohttp session")

def update_stats(self : Validator, synapses : dict[int, MarketSimulationStateUpdate]) -> None:
    """
    Updates miner request statistics maintained and published by the validator.

    Args:
        self (Validator): The intelligent markets simulation validator.
        synapses (dict[int, MarketSimulationStateUpdate]): Mapping of miner UIDs to their corresponding synapse updates.

    Returns:
        None
    """
    for uid, synapse in synapses.items():
        self.miner_stats[uid]['requests'] += 1
        if synapse.is_timeout:
            self.miner_stats[uid]['timeouts'] += 1
        elif synapse.is_failure or synapse.response is None:
            self.miner_stats[uid]['failures'] += 1
        elif synapse.is_blacklist:
            self.miner_stats[uid]['rejections'] += 1
        elif synapse.dendrite.process_time:
            self.miner_stats[uid]['call_time'].append(synapse.dendrite.process_time)

async def forward(self, synapse: MarketSimulationStateUpdate) -> List[FinanceAgentResponse]:
    """
    Forwards a market simulation state update to miner agents via POSIX IPC.

    Packages request data, sends it to the external query service, receives agent responses,
    updates miner statistics, and applies delay scoring.

    Args:
        self (Validator): The intelligent markets simulation validator.
        synapse (MarketSimulationStateUpdate): The simulation state data to forward to miner agents.

    Returns:
        List[FinanceAgentResponse]: List of agent responses generated by miners.
    """
    responses = []

    if self.deregistered_uids != []:
        response = FinanceAgentResponse(agent_id=self.uid)
        response.reset_agents(agent_ids=self.deregistered_uids)
        responses.append(response)

    bt.logging.info("Querying Miners...")

    if self.query_process.poll() is not None:
        bt.logging.error(f"Query service died with exit code {self.query_process.returncode}")
        bt.logging.error("Attempting to restart query service...")
        self._start_query_service()
        if self.query_process.poll() is not None:
            bt.logging.error("Failed to restart query service")
            return responses

    session_start = time.time()
    bt.logging.debug(f"Session configured ({time.time() - session_start:.4f}s)")

    data_start = time.time()
    request_data = {
        'books': synapse.books,
        'accounts': synapse.accounts,
        'notices': synapse.notices,
        'config': synapse.config.model_dump(mode='json'),
        'version': synapse.version,
        'timestamp': synapse.timestamp,
        'metagraph_axons': [
            {
                'hotkey': axon.hotkey,
                'coldkey': axon.coldkey,
                'ip': axon.ip,
                'port': axon.port,
                'ip_type': axon.ip_type,
                'protocol': axon.protocol,
            }
            for axon in self.metagraph.axons
        ],
        'deregistered_uids': list(self.deregistered_uids),
        'uid': self.uid,
        'miner_wealth': self.simulation.miner_wealth,
        'volume_decimals': self.simulation.volumeDecimals,
        'book_count': self.simulation.book_count,
        'volume_sums': {uid: dict(books) for uid, books in self.volume_sums.items()},
        'capital_turnover_cap': self.config.scoring.activity.capital_turnover_cap,
        'max_instructions_per_book': self.config.scoring.max_instructions_per_book,
    }
    bt.logging.info(f"Request Data Prepared ({time.time()-data_start:.4f}s).")

    query_start = time.time()
    try:
        try:
            await asyncio.to_thread(self.response_queue.receive, timeout=0.0)
            bt.logging.warning("Drained stale message from query response queue")
        except posix_ipc.BusyError:
            pass
        bt.logging.info(f"Drained Query Response Queue ({time.time()-query_start:.4f}s).")

        write_start = time.time()
        data_bytes = await asyncio.to_thread(pickle.dumps, request_data, protocol=5)
        bt.logging.info(f"Request data size: {len(data_bytes) / 1024 / 1024:.2f} MB")
        
        def write_request():
            self.request_mem.seek(0)
            self.request_mem.write(struct.pack('Q', len(data_bytes)))
            self.request_mem.write(data_bytes)
        
        await asyncio.to_thread(write_request)
        bt.logging.info(f"Wrote request data ({time.time()-write_start:.4f}s).")

        receive_start = time.time()
        await asyncio.to_thread(self.request_queue.send, b'query')
        timeout = self.config.neuron.global_query_timeout + 10
        message, _ = await asyncio.to_thread(self.response_queue.receive, timeout=timeout)
        bt.logging.info(f"Received Response ({time.time()-receive_start:.4f}s).")

        read_start = time.time()
        
        def read_response():
            self.response_mem.seek(0)
            size_bytes = self.response_mem.read(8)
            data_size = struct.unpack('Q', size_bytes)[0]
            result_bytes = self.response_mem.read(data_size)
            return pickle.loads(result_bytes)
        
        result = await asyncio.to_thread(read_response)
        bt.logging.info(f"Read response data ({time.time()-read_start:.4f}s).")

    except posix_ipc.BusyError:
        bt.logging.error(f"Query service response timeout after {timeout}s")
        return responses
    except Exception as e:
        bt.logging.error(f"Error communicating with query service: {e}")
        bt.logging.error(traceback.format_exc())
        return responses

    if not result['success']:
        bt.logging.error(f"Query service error: {result.get('error')}")
        if 'traceback' in result:
            bt.logging.error(f"Traceback: {result['traceback']}")
        return responses

    synapse_responses = result['responses']
    
    bt.logging.info(f"Query Completed ({time.time()-query_start:.4f}s).")
    
    start = time.time()
    update_stats(self, synapse_responses)
    bt.logging.info(f"Updated Stats ({time.time()-start:.4f}s).")

    start = time.time()
    responses.extend(set_delays(self, synapse_responses))
    bt.logging.info(f"Set Delays ({time.time()-start:.4f}s).")

    bt.logging.trace(f"Responses: {responses}")
    bt.logging.info(f"Received {result['validation_stats']['total_responses']} valid responses containing {result['validation_stats']['total_instructions']} instructions at {duration_from_timestamp(synapse.timestamp)} "
                f"({result['validation_stats']['success']} SUCCESS | {result['validation_stats']['timeouts']} TIMEOUTS | {result['validation_stats']['failures']} FAILURES).")

    return responses

async def notify(self : Validator, notices : List[FinanceEventNotification]) -> None:
    """
    Forwards finance event notifications to the appropriate miner agents.

    Uses the validator's dendrite to dispatch each event to the miner responsible
    for the associated agent, or to all miners if the event is broadcast.

    Args:
        self (Validator): The intelligent markets simulation validator.
        notices (List[FinanceEventNotification]): List of event notifications to dispatch.

    Returns:
        None
    """
    responses = []
    for notice in notices:
        axons = [self.metagraph.axons[notice.event.agentId]] if notice.event.agentId else self.metagraph.axons
        responses.extend(await self.dendrite(
            axons=axons,
            synapse=notice,
            timeout=1
        ))
    for response in responses:
        if response and response.acknowledged:
            bt.logging.info(f"{response[0].type} EventNotification Acknowledged by {response[0].axon.hotkey}")